{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Cell 1. Environment setup and experiment configuration**\n",
    "\n",
    "This cell initializes the computational environment and defines the experimental setting used throughout the analysis. It imports all required project modules and dependencies, specifies the data source, and sets the core experimental condition via the time period (PERIOD) and road type filter (TYPE_FILTER).\n",
    "\n",
    "To reproduce different results reported in the study, only the values of PERIOD and TYPE_FILTER need to be modified. All subsequent steps adapt automatically to these settings."
   ],
   "id": "fd0bc6eea89511c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from modules.data_utils import load_and_preprocess\n",
    "from modules.model_utils import train_model, cross_val_r2\n",
    "from modules.shap_stability_utils import shap_stability_check\n",
    "from modules.shap_utils import compute_shap\n",
    "from modules.draw_figure import plot_summary, plot_dependence\n",
    "\n",
    "from modules.config import DTYPE, FEATURE_COLS, DEPENDENCE_LIMITS, select_xgb_params\n",
    "from modules.io_utils import get_out_dirs, safe_feature_filename\n",
    "\n",
    "\n",
    "# ---- Change these two to switch experiments ----\n",
    "DATA = Path(\"data.csv\")\n",
    "PERIOD = \"night\"          # \"day\" or \"night\"\n",
    "TYPE_FILTER = None  # None or \"motorway\"/\"trunk\"/\"primary\"/\"secondary\"/\"tertiary\"/\"residential\"\n",
    "\n",
    "\n",
    "# ---- Outputs: auto folder naming by (period, type_filter) ----\n",
    "RUN_DIR, FIG_DIR, TAB_DIR, MODEL_DIR = get_out_dirs(\n",
    "    base_dir=Path(\"outputs\"),\n",
    "    period=PERIOD,\n",
    "    type_filter=TYPE_FILTER,\n",
    "    make=True,\n",
    ")\n",
    "\n",
    "# ---- Model hyperparameters: auto selected ----\n",
    "params = select_xgb_params(PERIOD, TYPE_FILTER)"
   ],
   "id": "6787f2e221094ce2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Cell 2. Data loading and preprocessing**",
   "id": "3e6a38786858f4b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X, X_display, y = load_and_preprocess(\n",
    "    DATA,\n",
    "    dtype=DTYPE,\n",
    "    feature_cols=FEATURE_COLS,\n",
    "    group_col=\"car_id\",\n",
    "    fe_residualize=True,\n",
    "    period=PERIOD,\n",
    "    cal=\"all\",\n",
    "    type_filter=TYPE_FILTER,\n",
    "    type_col=\"type\",\n",
    ")\n",
    "print(f\"Records after filtering: {len(X):,}\")"
   ],
   "id": "53cb24678fa321cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Cell 3：Cross-validation performance assessment**",
   "id": "5a5bbe960dfdff2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---- Cross-validation to assess model robustness ----\n",
    "cv_scores, cv_mean, cv_std = cross_val_r2(\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=100,   # keep consistent with final training\n",
    "    **params\n",
    ")\n",
    "\n",
    "print(\"Cross-validation R² scores (each fold):\", cv_scores)\n",
    "print(f\"Cross-validation mean R²: {cv_mean:.4f} ± {cv_std:.4f}\")"
   ],
   "id": "4cafd754e7133266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Cell 4. Final model training and evaluation**\n",
    "\n",
    "The final model is trained using a single train–validation–test split, with early stopping applied on the validation set. This trained model is used for all subsequent SHAP analyses and visualizations.\n",
    "\n",
    "In rare cases, model performance may appear suboptimal due to an unfavourable random split, which can lead to premature early stopping when the validation subset is not fully representative. This behaviour reflects sampling variability rather than a systematic model issue.\n",
    "If such a case occurs, adjusting the random_state parameter and re-running the training step is sufficient to recover stable performance.\n",
    "\n",
    "The final trained XGBoost model is saved to disk to ensure reproducibility of all downstream SHAP analyses without retraining."
   ],
   "id": "ae095d357b999c84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---- Final model training with train/validation/test split ----\n",
    "model, X_train, X_valid, X_test, y_train, y_valid, y_test = train_model(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    valid_size=0.1,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=100,\n",
    "    **params\n",
    ")\n",
    "\n",
    "# ---- Performance on validation and test sets ----\n",
    "r2_valid = r2_score(y_valid, model.predict(X_valid))\n",
    "r2_test = r2_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(f\"Validation R²: {r2_valid:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "\n",
    "# ---- Additional error metrics on the test set ----\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "# ---- Save final trained XGBoost model (for reproducibility) ----\n",
    "model_path = MODEL_DIR / \"xgb_model.json\"\n",
    "model.save_model(model_path)\n",
    "\n",
    "print(\"Final XGBoost model saved to:\", model_path)"
   ],
   "id": "34604f359e7dc1a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Cell 5. SHAP stability assessment**\n",
    "\n",
    "This cell evaluates the robustness of feature-attribution results by repeating SHAP computation on multiple resampled subsets and comparing the resulting feature-importance rankings. Stability is quantified using (i) Spearman rank correlation of mean absolute SHAP importances across repetitions, and (ii) the overlap rate among the top-K most important features."
   ],
   "id": "f3f7dad2c9cb5345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---- SHAP stability assessment via repeated sampling ----\n",
    "res = shap_stability_check(\n",
    "    model,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    explain_n=20000,        # number of samples explained in each repetition\n",
    "    repeats=5,              # number of repetitions for stability estimation\n",
    "    strata_cols=[],         # stratification columns (empty = random sampling)\n",
    "    use_fast_shap=True,     # use fast SHAP approximation for efficiency\n",
    "    background_n=800,       # only used when use_fast_shap=False\n",
    "    topk=10,                # top-K features used for overlap calculation\n",
    "    random_seed=42          # random seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"SHAP stability (Spearman ρ across repetitions): \"\n",
    "    f\"{res['rho_list']} | mean ± sd = {res['rho_mean']:.3f} ± {res['rho_std']:.3f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Top-{res['topk']} feature overlap ratios: \"\n",
    "    f\"{res['topk_overlap_list']} | mean = {res['topk_overlap_mean']:.3f}\"\n",
    ")"
   ],
   "id": "8a737f22a004f157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Cell 6：Final SHAP attribution and feature importance**",
   "id": "c94e369811daea98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---- Final SHAP attribution on a subsample of the test set ----\n",
    "X_test_shap = X_test.sample(\n",
    "    n=min(len(X_test), 5000),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "explainer, shap_values = compute_shap(\n",
    "    model,\n",
    "    X_train,\n",
    "    X_test_shap,\n",
    "    background_size=1000\n",
    ")\n",
    "\n",
    "# ---- Aggregate SHAP values across samples ----\n",
    "mean_shap = shap_values.mean(axis=0)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    \"feature\": X_test_shap.columns,\n",
    "    \"mean_shap\": mean_shap,\n",
    "    \"mean_abs_shap\": mean_abs_shap,\n",
    "    \"percentage\": mean_abs_shap / mean_abs_shap.sum() * 100,\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(\"Top features by mean absolute SHAP value:\")\n",
    "print(shap_importance_df.head(20))\n",
    "\n",
    "out_csv = TAB_DIR / \"shap_importance.csv\"\n",
    "shap_importance_df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"SHAP importance table saved to:\", out_csv)"
   ],
   "id": "67d953aac3f82c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ****# Cell 7：Visualization of SHAP results****",
   "id": "503737e734224f71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_display_test = X_display.loc[X_test_shap.index]\n",
    "\n",
    "# Summary plot\n",
    "summary_path = FIG_DIR / \"shap_summary.png\"\n",
    "plot_summary(shap_values, X_test_shap, str(summary_path))\n",
    "print(\"Saved:\", summary_path)\n",
    "\n",
    "# Dependence plots (loop)\n",
    "for feat, lim in DEPENDENCE_LIMITS.items():\n",
    "    fname = f\"{safe_feature_filename(feat)}_dependence.png\"\n",
    "    out_path = FIG_DIR / fname\n",
    "    plot_dependence(\n",
    "        shap_values,\n",
    "        X_test_shap,\n",
    "        feat,\n",
    "        filename=str(out_path),\n",
    "        display_features=X_display_test,\n",
    "        xlim=lim.get(\"xlim\"),\n",
    "        ylim=lim.get(\"ylim\"),\n",
    "    )\n",
    "\n",
    "print(\"Saved dependence plots to:\", FIG_DIR)\n"
   ],
   "id": "da175366c0a1dfa0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
